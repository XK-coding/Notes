# 如何衡量算法好坏

## 事后统计法：直接跑数据测试

- 优点：一目了然
- 缺点：依赖测试数据；比较依赖于硬件环境

## 事前分析法：
1.最差的执行情况
2.假设每行语句执行时间一样
3.计算出算法完成所需要的步骤数量

## 时间复杂度：
用来衡量一个算法的执行，随数据规模增大，而增长的时间成本
- 不依赖于环境因素

## 如何表示时间复杂度
- 假设要处理的数据规模是n，代码总的执行行数用函数f(n)来表示
- 为了对f(n)进行化简，找到一个变化趋势与之相近的表示法

## 大O表示法
- $c$, $c1$, $c2$ 都为一个常数
- $f(n)$是实际执行代码行数与n的函数
- $g(n)$是经过化简，变化趋势与$f(n)$ 一致的$n$的函数



## 已知f(n)来说，求g(n)

- 表达式中相乘的常量，可以省略
- 多项式中数量规模更小（低次项）的表达式
- 不同底数的对数，渐进上界可以用一个对数的$log_n$表示
- 类似的，对数的常数次幂可省略

## 常见大O表示法：

按时间复杂度从低到高：

- $O（1）$，常量时间，意味着算法时间不随数据规模而变化
- $o(log_(n))$，对数时间
- $o(n)$，线性时间，算法时间与数据规模成正比
- $o(n*log(n))$，拟线性时间
- $o(n^2)$指数时间
- $0(n!)$阶乘



## asymptotic upper bound

渐进上界：从某个常数$n0$开始，$c*g(n)$总是位于$f(n)$上方，那么记作$o(g(n))$



## asymptotic lower bound

渐进下界：从某个常数$n0$开始，$c*g(n)$总是位于$f(n)$下方，那么记作$omiga(g(n))$



## asymptotic tihgt bounds

渐进紧界：从某个常数$n0$开始，$f(n)$总是在$c1*g(n)$和$c2*g(n)$之间，记作$zita(g(n))$	



## 空间复杂度

与时间复杂度类似，一般也使用大$o$表示法来衡量：一个算法执行随数据规模增大，而增长的**额外**空间成本。

例如：如果需要常数个指针，那么额外占用的空间是$o(1)$